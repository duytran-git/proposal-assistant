# =============================================================================
# Proposal Assistant - Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values.
# All variables marked [REQUIRED] must be set for the app to start.
# =============================================================================

# -----------------------------------------------------------------------------
# SLACK CONFIGURATION [REQUIRED]
# -----------------------------------------------------------------------------

# Bot User OAuth Token - starts with xoxb-
# Found at: Slack App > OAuth & Permissions > Bot User OAuth Token
SLACK_BOT_TOKEN=xoxb-your-bot-token

# App-Level Token - starts with xapp-
# Found at: Slack App > Basic Information > App-Level Tokens
# Required scopes: connections:write
SLACK_APP_TOKEN=xapp-your-app-token

# Signing Secret - used to verify requests from Slack
# Found at: Slack App > Basic Information > App Credentials > Signing Secret
SLACK_SIGNING_SECRET=your-signing-secret

# -----------------------------------------------------------------------------
# GOOGLE CONFIGURATION [REQUIRED]
# -----------------------------------------------------------------------------

# Service Account credentials as JSON string
# Create at: Google Cloud Console > IAM & Admin > Service Accounts
# Required APIs: Google Drive API, Google Slides API
# Tip: Use single-line JSON or escape newlines
GOOGLE_SERVICE_ACCOUNT_JSON={"type": "service_account", "project_id": "...", ...}

# Root folder ID where proposals will be created
# This is the folder ID from the Google Drive URL
# Example: https://drive.google.com/drive/folders/1ABC... -> 1ABC...
GOOGLE_DRIVE_ROOT_FOLDER_ID=1ABC...

# -----------------------------------------------------------------------------
# LLM CONFIGURATION [REQUIRED]
# -----------------------------------------------------------------------------

# Ollama API base URL
# Local: http://localhost:11434/v1
# Remote: http://your-server:11434/v1
OLLAMA_BASE_URL=http://localhost:11434/v1

# Ollama model to use for proposal generation
# Recommended: qwen2.5:14b, llama3.1:8b, mistral:7b
OLLAMA_MODEL=qwen2.5:14b

# -----------------------------------------------------------------------------
# TEMPLATE CONFIGURATION [REQUIRED]
# -----------------------------------------------------------------------------

# Google Slides template ID for proposals
# This is the file ID from the Google Slides URL
# Example: https://docs.google.com/presentation/d/1XYZ.../edit -> 1XYZ...
PROPOSAL_TEMPLATE_SLIDE_ID=1XYZ...

# -----------------------------------------------------------------------------
# OPTIONAL CONFIGURATION
# -----------------------------------------------------------------------------

# Context window size for Ollama (tokens)
# Higher values allow longer transcripts but use more memory
# Default: 32768
OLLAMA_NUM_CTX=32768

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# Environment name: development, staging, production
# Affects behavior like error verbosity
# Default: development
ENVIRONMENT=development

# -----------------------------------------------------------------------------
# CLOUD LLM FALLBACK [OPTIONAL]
# -----------------------------------------------------------------------------
# Configure a cloud LLM provider as fallback when Ollama is unavailable.
# Only used if CLOUD_PROVIDER is set.

# Cloud provider to use: "openai" or "anthropic"
# Leave empty to disable cloud fallback
CLOUD_PROVIDER=

# OpenAI configuration (if CLOUD_PROVIDER=openai)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o

# Anthropic configuration (if CLOUD_PROVIDER=anthropic)
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-sonnet-4-20250514
